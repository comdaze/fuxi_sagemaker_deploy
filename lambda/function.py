import json
import boto3
from datetime import datetime
import os

def lambda_handler(event, context):
    """
    ä¼˜åŒ–ç‰ˆLambdaå¤„ç†å‡½æ•°
    - ä½¿ç”¨è‡ªå®šä¹‰Dockeré•œåƒçš„SageMakeræ¨¡å‹
    - æ”¯æŒç¯å¢ƒå˜é‡é…ç½®
    - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—
    """
    
    s3_client = boto3.client('s3')
    sagemaker_client = boto3.client('sagemaker')
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    model_bucket = os.environ.get('MODEL_BUCKET')
    sagemaker_role = os.environ.get('SAGEMAKER_ROLE')
    model_name = os.environ.get('MODEL_NAME', 'fuxi-weather-model-optimized')
    instance_type = os.environ.get('INSTANCE_TYPE', 'ml.g4dn.2xlarge')
    instance_count = int(os.environ.get('INSTANCE_COUNT', '1'))
    
    print(f"ğŸš€ Lambdaå‡½æ•°å¯åŠ¨ - ä½¿ç”¨ä¼˜åŒ–çš„Dockeré•œåƒ")
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  æ¨¡å‹å­˜å‚¨æ¡¶: {model_bucket}")
    print(f"  SageMakerè§’è‰²: {sagemaker_role}")
    print(f"  æ¨¡å‹åç§°: {model_name}")
    print(f"  å®ä¾‹ç±»å‹: {instance_type}")
    print(f"  å®ä¾‹æ•°é‡: {instance_count}")
    
    # éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
    if not model_bucket:
        print("âŒ é”™è¯¯: æœªè®¾ç½®MODEL_BUCKETç¯å¢ƒå˜é‡")
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'MODEL_BUCKET environment variable not set'})
        }
    
    if not sagemaker_role:
        print("âŒ é”™è¯¯: æœªè®¾ç½®SAGEMAKER_ROLEç¯å¢ƒå˜é‡")
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'SAGEMAKER_ROLE environment variable not set'})
        }
    
    processed_jobs = []
    
    # å¤„ç†æ¯ä¸ªS3äº‹ä»¶è®°å½•
    for record in event['Records']:
        try:
            # è·å–è§¦å‘äº‹ä»¶çš„æ¡¶åå’Œå¯¹è±¡é”®
            bucket_name = record['s3']['bucket']['name']
            object_key = record['s3']['object']['key']
            
            print(f"ğŸ“¥ å¤„ç†S3äº‹ä»¶: s3://{bucket_name}/{object_key}")
            
            # ç¡®ä¿æ˜¯_SUCCESSæ–‡ä»¶
            if not object_key.endswith('_SUCCESS'):
                print(f"â­ï¸  è·³è¿‡é_SUCCESSæ–‡ä»¶: {object_key}")
                continue
                
            # è·å–_SUCCESSæ–‡ä»¶æ‰€åœ¨çš„ç›®å½•è·¯å¾„
            folder_path = os.path.dirname(object_key)
            print(f"ğŸ“ å¤„ç†ç›®å½•: {folder_path}")
            
            # åˆ—å‡ºè¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰.ncæ–‡ä»¶
            response = s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix=folder_path + '/',
                Delimiter='/'
            )
            
            nc_files = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    file_key = obj['Key']
                    if file_key.endswith('.nc'):
                        # ä¿å­˜å®Œæ•´çš„S3è·¯å¾„
                        s3_path = f's3://{bucket_name}/{file_key}'
                        nc_files.append(s3_path)
            
            print(f"ğŸ” æ‰¾åˆ° {len(nc_files)} ä¸ª.ncæ–‡ä»¶")
            
            if len(nc_files) == 0:
                print("âš ï¸  æœªæ‰¾åˆ°.ncæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
                continue
            
            # æŒ‰æ–‡ä»¶åæ’åº
            nc_files.sort()
            
            # åˆ›å»ºJSONLå†…å®¹ï¼Œæ¯ä¸¤ä¸ªæ–‡ä»¶ä¸ºä¸€ç»„
            jsonl_lines = []
            for i in range(0, len(nc_files), 2):
                if i + 1 < len(nc_files):
                    line_data = {
                        "filename1": nc_files[i],
                        "filename2": nc_files[i + 1]
                    }
                    jsonl_lines.append(json.dumps(line_data))
            
            # å¦‚æœncæ–‡ä»¶æ•°é‡ä¸ºå¥‡æ•°ï¼Œå¤„ç†æœ€åä¸€ä¸ªæ–‡ä»¶
            if len(nc_files) % 2 == 1:
                line_data = {
                    "filename1": nc_files[-1],
                    "filename2": nc_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºå¤‡ç”¨
                }
                jsonl_lines.append(json.dumps(line_data))
            
            print(f"ğŸ“ ç”Ÿæˆ {len(jsonl_lines)} è¡ŒJSONLæ•°æ®")
            
            # åˆ›å»ºJSONLæ–‡ä»¶å†…å®¹
            jsonl_content = '\n'.join(jsonl_lines)
            
            # ä»ncæ–‡ä»¶åä¸­æå–æ—¥æœŸ
            if nc_files:
                # ä»S3è·¯å¾„ä¸­æå–æ–‡ä»¶å
                first_file_name = os.path.basename(nc_files[0])
                # å‡è®¾æ–‡ä»¶åæ ¼å¼å¦‚ï¼š20240101_00.nc æˆ– 2024010100.nc
                # æå–æ—¥æœŸéƒ¨åˆ†
                if '_' in first_file_name:
                    date_str = first_file_name.split('_')[0][:8]
                elif '.' in first_file_name:
                    date_str = first_file_name.split('.')[0][:8]
                else:
                    date_str = datetime.now().strftime('%Y%m%d')
            else:
                date_str = datetime.now().strftime('%Y%m%d')
            
            print(f"ğŸ“… æå–æ—¥æœŸ: {date_str}")
            
            # è®¾ç½®S3è·¯å¾„
            s3_prefix = 'sagemaker/fuxi'
            
            # åˆ›å»ºå¸¦æ—¥æœŸå’Œæ—¶é—´æˆ³çš„JSONLæ–‡ä»¶å
            timestamp = int(datetime.now().timestamp())
            jsonl_file_name = f'input/{date_str}-{timestamp}.jsonl'
            s3_data_path = f's3://{model_bucket}/{s3_prefix}/{jsonl_file_name}'
            s3_output_path = f's3://{model_bucket}/{s3_prefix}/output/{date_str}-{timestamp}/'
            
            # ä¸Šä¼ JSONLæ–‡ä»¶åˆ°S3
            try:
                s3_client.put_object(
                    Bucket=model_bucket,
                    Key=f'{s3_prefix}/{jsonl_file_name}',
                    Body=jsonl_content.encode('utf-8'),
                    ContentType='application/x-jsonlines'
                )
                print(f"âœ… JSONLæ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {s3_data_path}")
            except Exception as e:
                print(f"âŒ JSONLæ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
                continue
            
            # åˆ›å»ºSageMakeræ‰¹é‡è½¬æ¢ä»»åŠ¡
            transform_job_name = f"fuxi-optimized-{date_str}-{timestamp}"
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            try:
                sagemaker_client.describe_model(ModelName=model_name)
                print(f"âœ… ç¡®è®¤æ¨¡å‹å­˜åœ¨: {model_name}")
            except sagemaker_client.exceptions.ClientError as e:
                if 'ValidationException' in str(e):
                    print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_name}")
                    print("ğŸ’¡ è¯·å…ˆåˆ›å»ºä½¿ç”¨è‡ªå®šä¹‰Dockeré•œåƒçš„SageMakeræ¨¡å‹")
                    continue
                else:
                    raise e
            
            try:
                # ä½¿ç”¨ä¼˜åŒ–çš„é…ç½®åˆ›å»ºæ‰¹é‡è½¬æ¢ä»»åŠ¡
                response = sagemaker_client.create_transform_job(
                    TransformJobName=transform_job_name,
                    ModelName=model_name,  # ä½¿ç”¨è‡ªå®šä¹‰Dockeré•œåƒçš„æ¨¡å‹
                    TransformInput={
                        'DataSource': {
                            'S3DataSource': {
                                'S3DataType': 'S3Prefix',
                                'S3Uri': s3_data_path
                            }
                        },
                        'ContentType': 'application/json',
                        'SplitType': 'Line'
                    },
                    TransformOutput={
                        'S3OutputPath': s3_output_path,
                        'Accept': 'application/json',
                        'AssembleWith': 'Line'
                    },
                    TransformResources={
                        'InstanceType': instance_type,
                        'InstanceCount': instance_count
                    },
                    Environment={
                        # ä¼˜åŒ–çš„ç¯å¢ƒå˜é‡é…ç½®
                        'TS_DEFAULT_WORKERS_PER_MODEL': '1',
                        'TS_DEFAULT_RESPONSE_TIMEOUT': '3600',
                        'SAGEMAKER_MODEL_SERVER_TIMEOUT': '3600',
                        'SAGEMAKER_MODEL_SERVER_WORKERS': '1',
                        # FuXiæ¨¡å‹ç‰¹å®šé…ç½®
                        'FUXI_MODEL_BUCKET': model_bucket,
                        'FUXI_MODEL_PREFIX': 'sagemaker/fuxi',
                        'SAGEMAKER_PROGRAM': 'inference.py'
                    },
                    Tags=[
                        {
                            'Key': 'Project',
                            'Value': 'FuXi-Weather-Forecast'
                        },
                        {
                            'Key': 'Environment',
                            'Value': os.environ.get('ENVIRONMENT', 'dev')
                        },
                        {
                            'Key': 'OptimizedImage',
                            'Value': 'true'
                        },
                        {
                            'Key': 'Date',
                            'Value': date_str
                        }
                    ]
                )
                
                job_info = {
                    'job_name': transform_job_name,
                    'job_arn': response['TransformJobArn'],
                    'input_path': s3_data_path,
                    'output_path': s3_output_path,
                    'date': date_str,
                    'nc_files_count': len(nc_files)
                }
                
                processed_jobs.append(job_info)
                
                print(f"âœ… SageMakeræ‰¹é‡è½¬æ¢ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {transform_job_name}")
                print(f"ğŸ“ ä»»åŠ¡ARN: {response['TransformJobArn']}")
                print(f"ğŸ“¥ è¾“å…¥è·¯å¾„: {s3_data_path}")
                print(f"ğŸ“¤ è¾“å‡ºè·¯å¾„: {s3_output_path}")
                print(f"ğŸ·ï¸  ä½¿ç”¨ä¼˜åŒ–é•œåƒ: {model_name}")
                
            except Exception as e:
                print(f"âŒ SageMakeræ‰¹é‡è½¬æ¢ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")
                print("ğŸ’¡ è¯·æ£€æŸ¥:")
                print(f"  - æ¨¡å‹æ˜¯å¦å­˜åœ¨: {model_name}")
                print(f"  - è§’è‰²æƒé™: {sagemaker_role}")
                print(f"  - å®ä¾‹é…é¢: {instance_type}")
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯ä¾›è°ƒè¯•
                print(f"ğŸ“Š è¯¦ç»†ä¿¡æ¯:")
                print(f"  è¾“å…¥è·¯å¾„: {s3_data_path}")
                print(f"  è¾“å‡ºè·¯å¾„: {s3_output_path}")
                print(f"  è§’è‰²ARN: {sagemaker_role}")
                print(f"  å®ä¾‹ç±»å‹: {instance_type}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†è®°å½•æ—¶å‡ºé”™: {e}")
            print(f"ğŸ“Š è®°å½•è¯¦æƒ…: {json.dumps(record, indent=2)}")
            continue
    
    # è¿”å›å¤„ç†ç»“æœ
    result = {
        'statusCode': 200,
        'body': json.dumps({
            'message': 'Lambda function executed successfully with optimized Docker image',
            'processed_records': len(event['Records']),
            'created_jobs': len(processed_jobs),
            'jobs': processed_jobs,
            'optimizations': {
                'custom_docker_image': True,
                'pre_installed_dependencies': True,
                'faster_startup': True,
                'model_name': model_name
            }
        }, indent=2)
    }
    
    print(f"ğŸ‰ Lambdaæ‰§è¡Œå®Œæˆ:")
    print(f"  å¤„ç†è®°å½•æ•°: {len(event['Records'])}")
    print(f"  åˆ›å»ºä»»åŠ¡æ•°: {len(processed_jobs)}")
    print(f"  ä½¿ç”¨ä¼˜åŒ–é•œåƒ: {model_name}")
    
    return result
